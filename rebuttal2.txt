
Coordination is a programming language design issue that requires novel approaches based on sound formal foundations. The implementation challenges are important but not as important from a PL perspective. While systems such as Galois and Elixir solve of those challenges, they are not programming languages on their own right and thus do not solve the programming language design issue. Our solution to this PL design challenge fits the scope of PLDI fairly well. We think there is some mismatch between this important contribution and the reviewer’s perspective on the material. 

CLM makes scheduling and partitioning an integral part of a declarative programming language, indistinguishable and semantically equivalent to regular computation, allowing the programmer to write arbitrarily complex scheduling policies that are dynamic. Because the paper was written from this PL perspective, we unfairly neglected important related work.

Another purpose of the paper is to show the expressive power of making coordination a first class programming construct and thus we chose to include five examples to give readers a flavor of the power of CLM. This approach highlights the conciseness and expressiveness of CLM as well as the readability of a high-level declarative approach to fine-tune the performance of a program. Each reviewer asked for more (but different) information which would require us to remove something in the paper.  We will happily take advice from the committee about what we should remove to make room for something else.

Related Work:

The reviews pointed out numerous systems that we did not cite.  Please note that CLM stands alone in
- making coordination (both scheduling and partitioning) a first-class programming construct.
- supporting data-driven dynamic (at run-time) coordination, particularly for irregular data structures.
- is actually a declarative programming language and not a runtime system (Galois, Elixir and others), solving both the implementation and design issues.

We do not claim novelty in the mechanisms, but rather in how they are integrated into a declarative language - as a first class entity.  We will do a better job of showing where the ideas come from.

In reference to works cited by the reviewers:
- Halide supports distinct coordination, but only as "pragmas" in the domain of image processing, i.e., regular data-structures.
- Galois supports a rich set of schedulers through customizable containers (see: Nguyen&Pingali), but it requires extra-language mechanisms to do things such as determining the location of data.
- Elixir's uses a pre-defined set of schedulers and limits coordination to scheduling.
- Grace supports scheduling through priorities.  (It is very much like GraphLab)
   - Ligra, also oriented towards graph processing, only handles partitioning.
   - Cilk, OpenMP and TBB all provide low-level imperative approaches for coordination.

   We will expand the related work section, but stress the unique nature of CLM which results in clean concise coordination, e.g., we can write the Splash scheduler used for Splash BP less than 60 lines (versus 500 in GraphLab).  It is hard (or impossible) to write in all the above languages.

   Experiments:

   Mea Culpa on not explaining the superlinear speed-up.  We didn't implement the randomized scheduler needed for the best sequential implementation.  We will address this in the final version.

   We did compare CLM to an optimized C++ implementation of 2 programs (HT and SBP): The CLM implementations are 1.8X-3X slower, but scale equally well.  Our focus was on expressiveness and scalability, not raw performance. (CLM is currently interpreted by an unoptimized virtual machine. It could even be compiled.)  From an expressiveness point of view, the GraphLab scheduler is 500 lines of customized library code.  CLM's version is less than 1 page!  If requested, we can also include a third-party solution to SSSP.  As well as including several different synthetic graphs to test the scalability over different data sets.

We can include comparisons to sequential solutions:
   - interpreted solutions (Python which is 2x-10x slower than CLM)
   - compiled solutions in C (which is 2-10x faster depending on the program)

Other Stuff (And addressing some of the smaller, but interesting points taken up by the reviewers):

Please refer to 1st response for the other points.

-> reviewer D:

- Small increment over Meld: we agree that this is true on the surface since the language is actually the same, but we do not agree that this is a point against since the language is able to describe normal computation and coordination using the same constructs. However, the runtime system actually looks quite different because now we have to deal with programmable scheduling and data partitioning. These two coordination mechanisms required significant changes in the implementation and compilation with the introduction of different queues for nodes and the ability to move and pin nodes to threads.
- CLM target: our current target is shared memory multi-cores. However the CLM programming model fits and is easily ported to clusters of computers. It’s just a matter of implementing a suitable runtime system for those architectures.
- Contribution of CLM: Galois and many others are not declarative programming languages. CLM solves a problem of programming language design by seamlessly combining computation and coordination into a single declarative programming model. Galois is a runtime system and does not solve this particular design problem.
- Technical challenges: there is a PL design language: how to design a declarative language that allows the programmer to dynamically coordinate execution while keeping the language declarative; we show that linear logic allows us to do this easily. There is an implementation challenge where we had to add support for all the coordination directives.
- Proofs: for most programs they do not complicate the proofs. However, for programs such as SBP, you have to take coordination into account because it changes how the program is computed.

Reviewer E:

- Programming efficiency: true, but we see this as a positive point since most declarative languages do not allow such control.
- Data layout: the data layout/node placement is changed by using action facts such as set-cpu or set-static. Set-cpu moves the node to another thread while set-static pins the node to a thread.
- inplace update: it can be done by analyzing how facts are used in the rules. If one fact fires a rule that updates the argument of another fact, then we could compile code that would update directly the argument of such fact instead of performing standard rule derivation.

-> reviewer B and E:

- The difference between Regular/Regular, Coordinated/Coordinated, Coordinated/Regular:
   - Regular/Regular: speedup of the unannotated (e.g.., regular) program on n-processors over the unannotated program on 1 processor.
   - Coordinated/Regular: speedup of the coordinated program on       n-processors over the unannotated (e.g., regular program) on 1       processor.
   - Coordinated/Coordinated: speedup of the coordinated program on       n-processors over the coordinated program on 1 processor.

Finally, we note that CLM is noteworthy since it is not restricted to shared memory systems and can be easily extended to distributed systems. The use of linear logic, a sound logical framework, has allowed us to easily prove properties about programs using coordination.
We thank the reviewers for the time and expertise they have invested in these reviews.  We will of course avail ourselves of all the comments on presentation, grammar, etc.  Again, many thanks.
