Coordination is an important programming language design issue, especially concerning declarative languages and parallelism. Our contribution makes dynamic coordination a first class entity of a declarative language and semantically equivalent to computation. Like reviewer B mentioned, this orthogonal design for writing coordinated algorithms will be of interest to many in the PLDI community. Unfortunately, there has been some misunderstanding between this important contribution and the other reviewer's perspective on the material.

Each reviewer asked for more (but different) information which would require us to remove something in the paper. We could have included more experiments and data sets but instead we decided to include five programs that give readers a flavor of the power of CLM. This approach highlights the conciseness and expressiveness of CLM as well as the readability of a high-level declarative approach to fine-tune the performance of programs. Our results show that CLM is competitive (2-3x) against GraphLab and performs reasonably well against C++ (2-10x slower). [See our first rebuttal for more detail]

We wrote the paper from a language perspective and thus some systems were unfairly neglected. We will include them in the final paper.   While those systems solve many important implementation issues, the programming language aspect remains unsolved. In Brief (See first response for more detail):
- Halide supports distinct coordination, but only as "pragmas" in the domain of image processing, i.e., regular data-structures.
- Galois supports a rich set of schedulers through customizable containers (see: Nguyen&Pingali), but it requires extra-language mechanisms to do things such as determining the location of data.
- Elixir's uses a predefined set of schedulers and limits coordination to scheduling.
- Grace supports scheduling through priorities (it is very much like GraphLab).
- Ligra, also oriented towards graph processing, only handles partitioning.
- Cilk, OpenMP and TBB all provide low-level imperative approaches for coordination.

CLM distinguishes itself by integrating both scheduling and partitioning into a declarative language as a first class entity. In particular CLM stands alone in:
- supporting data-driven dynamic (at run-time) coordination, particularly for irregular data structures.
- actually being a declarative programming language and not a runtime system, solving both the implementation and design issues.
- being able to specify complex coordination programs such as SBP in less than 60 lines (versus 500 in GraphLab). It is hard (or impossible) to write it in all the above languages.

REVIEWER D:

- Small increment over Meld: It is the beauty of our approach that the integration of coordination appears to be a small increment.  While it appears to be a small increment on the surface the ability to specify coordination in a first class manner is a significant contribution requiring major changes to both the runtime and compiler.

- CLM target: our current target is shared memory multicores. However, the CLM programming model fits and is easily ported to clusters of computers. 

- Contribution of CLM: Galois and many others are not declarative languages. CLM solves the language design issue by seamlessly combining computation and coordination into a single declarative model. Galois is a runtime system and does not solve this particular design problem.

- Technical challenges: The PL design issue is: how to design a declarative language that allows the programmer to dynamically   coordinate execution while keeping the language declarative; we show   that linear logic allows us to do this easily. The implementation   challenge is in supporting the coordination directives.

- Proofs: for most programs they do not complicate the   proofs. However, for programs such as SBP, you have to take coordination into account because it changes how the program is   computed.

REVIEWER E:

- Programming efficiency: No more or less then any other language, but unlike other declarative languages the programmer does get control if she wants it.

- Data layout: the data layout/node placement is changed by using action facts such as set-cpu or set-static. Set-cpu moves the node to another thread while set-static pins the node to a thread.

- inplace update: it can be done by analyzing how facts are used in the rules. If one fact fires a rule that updates the argument of another fact, then we could compile code that would update directly the argument of such fact instead of performing standard rule derivation.

- The difference between Regular/Regular, Coordinated/Coordinated, Coordinated/Regular: This is confusing and will be clearer in the final paper.  

   - Regular/Regular: speedup of the unannotated (e.g.., regular) program on n-processors over the unannotated program on 1 processor.

   - Coordinated/Regular: speedup of the coordinated program on n-processors over the unannotated (e.g., regular program) on 1 processor.

   - Coordinated/Coordinated: speedup of the coordinated program on n-processors over the coordinated program on 1 processor.

REVIEWER A, B and C: please refer to 1st response.

We thank the reviewers for the time and expertise they have invested
in these reviews.  We will happily take advice from the committee on
ways to improve our paper.


LocalWords:  PLDI CLM GraphLab Halide pragmas customizable Pingali
LocalWords:  pre Ligra Cilk OpenMP TBB runtime SBP multi cpu inplace
LocalWords:  unannotated
