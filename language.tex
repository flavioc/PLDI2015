Coordinated Linear Meld (CLM) is a forward-chaining linear logic programming
language based on LM~\cite{cruz-iclp14}.
Programs consist of a set of \emph{rules} and a \emph{database of facts}.
Rules such as \texttt{a(X), b(Y) -o c(X, Y)} can be read as follows: if fact \texttt{a(X)}
and fact \texttt{b(Y)} exist in the database then \texttt{c(X, Y)} is added to
the database. The expression \texttt{a(X), b(Y)} is called the \emph{body} of
the rule and \texttt{c(X, Y)} is the \emph{head} of the rule.
A fact is a predicate, e.g., \texttt{a}, \texttt{b} or \texttt{c}, and its
associated tuple of values, e.g., the concrete values of \texttt{X} and
\texttt{Y}, substitued for the
arguments. Since CLM uses linear logic as its foundation, we distinguish between
\emph{linear} and \emph{persistent facts}. Linear facts are deleted during the
process of deriving rule, while persistent facts are not.
Program execution starts by adding the \emph{axioms} (the initial facts) of the program to the database.
Next, the rules are recursively applied and the database is updated by adding
new facts or deleting facts used during rule derivation.
When no more rules are applicable, the program terminates.

CLM has been designed for writing programs that operate on graphs. CLM partitions
the database by using the first argument of each fact. The first argument has
type \emph{node} and represents a node in the graph. To achieve concurrency,
our implementation partitions the database by the first argument, e.g.,
the fact \texttt{f(@1, 2)} is stored in node \texttt{@1}, while
fact \texttt{p(@2)} is stored in node \texttt{@2}. CLM restricts the body of
every rule to facts with the same node so that nodes can derive rules
independently. Although the body is restricted, the head of the rule may refer
to any node as long as that node is refered to somewhere in the body. This allows
\scare{communication} between nodes during rule derivation, since a node may
\scare{send} a fact to another node.  Rule restrictions in turn make CLM
implicitly parallel because nodes are able to compute independently. This makes
CLM non-deterministic since nodes can be picked to run in any order, affecting
which rules are applied and which facts are deleted or derived.

To make these ideas concrete, we present a simple
program: the single source shortest path program~(SSSP). Later in the paper, we
add coordination facts to improve the execution of the program.

The SSSP program in Fig.~\ref{code:shortest_path_program} starts (lines 1-3)
with the declaration of the predicates. Predicates specify the facts
used in the program. The first predicate, \texttt{edge}, is a persistent
predicate that describes the relationship between the nodes of the graph,
where the third argument represents the weight of the edge (the
\texttt{route} modifier informs the compiler that the \texttt{edge} predicate
determines the structure of the graph).
The predicates \texttt{shortest} and \texttt{relax} are
specified as linear facts and thus are deleted when deriving new facts.  The
algorithm computes the shortest distance from node
\texttt{@1} to all other nodes in the graph. Every node has a
\texttt{shortest} fact that is improved with new \texttt{relax} facts.  Lines
5-9 declare the axioms of the program: \texttt{edge} facts describe the
graph; \texttt{shortest(A, +00, [])} is the initial shortest distance
(infinity) for all nodes; and \texttt{relax(@1, 0, [@1])} starts the
algorithm by setting the initial distance from \texttt{@1} to \texttt{@1} to be
0.

\begin{topfig}
\scriptsize\begin{Verbatim}[numbers=left]
type route edge(node, node, int).
type linear shortest(node, int, list int).
type linear relax(node, int, list int).

!edge(@1, @2, 3). !edge(@1, @3, 1).
!edge(@3, @2, 1). !edge(@3, @4, 5).
!edge(@2, @4, 1).
shortest(A, +00, []).
relax(@1, 0, [@1]).

shortest(A, D1, P1), D1 > D2, relax(A, D2, P2)
   -o shortest(A, D2, P2),
      {B, W | !edge(A, B, W) |
         relax(B, D2 + W, P2 ++ [B])}.

shortest(A, D1, P1), D1 <= D2, relax(A, D2, P2)
   -o shortest(A, D1, P1).
\end{Verbatim}
  \scap{code:shortest_path_program}{Single Source Shortest Path program code.}
\end{topfig}
\normalsize

The first rule of the program (lines 11-14) reads as following: if the current
\texttt{shortest} path \texttt{P1} with distance \texttt{D1} is larger
than a new path \texttt{relax} with distance \texttt{D2}, then replace the
current shortest path with \texttt{D2}, delete the new \texttt{relax} path and
propagate new paths to the neighbors (lines 14-15) using a \emph{comprehension}.
The comprehension iterates over the edges of node \texttt{A} and derives a new
\texttt{relax} fact for each node \texttt{B} with the distance \texttt{D2 + W},
where \texttt{W} is the weight of the edge. For
example, in Fig.~\ref{fig:shortest_path_program}~(a) we apply rule 1 in node
\texttt{@1} where two new \texttt{relax} facts are derived at node \texttt{@2}
and \texttt{@3}. Fig.~\ref{fig:shortest_path_program}~(b) is the result after
applying the same rule but at node \texttt{2}.

\begin{figure*}[ht]
\begin{center}
  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures/shortest2}}
  \hspace{0.4cm}
  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures/shortest3}}
  \hspace{0.4cm}
  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures/shortest8}}
\end{center}
\scap{fig:shortest_path_program}{Graphical representation of the SSSP program. Figure (a) represents the
   program after propagating initial distance at node \texttt{@1}, followed by
   Figure (b) where the first rule is applied in node \texttt{@3}. Figure (c)
   represents the state of the final program, where all the shortest paths
   have been computed.}
\end{figure*}

The second rule of the program (lines 16-17) is read as following: if the
current shortest path \texttt{D1} is shorter than the new path \texttt{D2} then
delete the new \texttt{relax} fact and keep the old shortest path.

There are many opportunities for concurrency in the SSSP program. For instance,
after applying rule 1 in Fig.~\ref{fig:shortest_path_program}~(a), it is
possible to either apply rules in either node \texttt{@2} or node
\texttt{@3}. This decision depends largely on implementation factors such as node
partitioning and number of threads in the system.
Still, it is easy to prove that no matter the scheduling used,
the final result present in Fig.~\ref{fig:shortest_path_program}~(c) is achieved.

%On the other hand, CLM has no natural matching of data and computation to workers (processes, threads),
%since nodes are a program abstraction and part of the program's logic.
%We view the set of nodes as a graph data structure where workers will perform work.
%A worker is able to process any node, although a node cannot be computed by more than one worker
%at the same time. This disallows the manipulation of a node by multiple workers.
