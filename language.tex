Linear Meld (LM) is a forward-chaining linear logic programming
language~\cite{cruz-iclp14} with roots on Datalog~\cite{Ramakrishnan93asurvey}.
Programs consist of a set of \emph{rules} and a \emph{database of facts}.
Rules such as \texttt{a(X), b(Y) -o c(X, Y)} can be read as follows: if fact \texttt{a(X)}
and fact \texttt{b(Y)} exist in the database then \texttt{c(X, Y)} is added to
the database. The expression \texttt{a(X), b(Y)} is called the \emph{body} of
the rule and \texttt{c(X, Y)} is the \emph{head} of the rule.
A fact is a predicate and its associated tuple of values, representing the
arguments. Since LM uses linear logic as its foundation, we distinguish between
\emph{linear} and \emph{persistent facts}. Linear facts are deleted during the
process of deriving rule, while persistent facts are not.
Program execution starts by adding the \emph{axioms} (the initial facts) of the program to the database.
Next, the rules are recursively applied and the database is updated with new and
deleted facts. When no more rules are applicable, the program terminates.

LM has been designed for writing programs that operate on graphs. LM partitions
the database by using the first argument of each fact. The first argument is
typed as a \emph{node} and represents a node in the graph. For instance, the
fact \texttt{f(@1, 2)} is stored in node \texttt{@1}, while fact \texttt{p(@2)}
is stored in node \texttt{@2}. LM restricts
the body of every rule to only refer to the same node so that nodes can derive
rules independently. Although the body is restricted, the head of the
rule may refer to any node as long as the node is refered somewhere in the
body. This allows communication between nodes during rule derivation, since a
node must send a fact to another node.
Rule restrictions in turn make LM implicitly parallel because nodes are able to
compute independently as long as they have new facts to be applied in rules.
This makes LM non-deterministic since nodes can be picked to run in any order,
affecting which rules are applied and which facts are deleted or derived.

In order to fully understand how the language works, we present a very simple
algorithm: the single source shortest path program~(SSSP). Later in the paper, we
add coordination facts to improve the execution of the program.

The SSSP program in Fig.~\ref{code:shortest_path_program} starts (lines 1-3)
with the declaration of the predicates. Predicates specify the kinds of facts
used in the program. The first predicate, \texttt{edge}, is a persistent
predicate that describes the
relationship between the nodes of the graph, where the third argument represents
the weight of the edge
(the \texttt{route} modifier informs the compiler about the structure of the
program graph). The predicates \texttt{shortest} and \texttt{relax} are specified
as linear facts and thus are deleted when deriving new facts.
The idea of the algorithm is to compute the shortest distance from node
\texttt{@1} to all other nodes in the graph. Every node has a \texttt{shortest}
fact that is improved with new \texttt{relax} facts.
Lines 5-9 declare the axioms of the program: \texttt{edge} facts describe the
graph; \texttt{shortest(A, +00, [])} is the initial shortest distance (infinity)
for all nodes; and \texttt{relax(@1, 0, [@1])} starts the algorithm with the
initial distance from \texttt{@1} to \texttt{@1}.

\begin{figure}[h!]
\scriptsize\begin{Verbatim}[numbers=left]
type route edge(node, node, int).
type linear shortest(node, int, list int).
type linear relax(node, int, list int).

!edge(@1, @2, 3). !edge(@1, @3, 1).
!edge(@3, @2, 1). !edge(@3, @4, 5).
!edge(@2, @4, 1).
shortest(A, +00, []).
relax(@1, 0, [@1]).

relax(A, D1, P1), shortest(A, D2, P2),
D1 < D2
   -o shortest(A, D1, P1),
      {B, W | !edge(A, B, W) |
         relax(B, D1 + W, P1 ++ [B])}.

relax(A, D1, P1), shortest(A, D2, P2),
D1 >= D2
   -o path(A, D2, P2).
\end{Verbatim}
  \caption{Single Source Shortest Path program code.}
  \label{code:shortest_path_program}
\end{figure}
\normalsize

The first rule of the program (lines 11-15) replaces the current path in
\texttt{shortest} with a shorter one in \texttt{relax}. The rule deletes both
\texttt{relax} and \texttt{shortest} facts and derives a new \texttt{shortest}
fact. In lines 14-15, we have a \emph{comprehension} where the program iterates
over the edges of node \texttt{A} and derives a new \texttt{relax} fact at
\texttt{B} with the new shorter distance plus the weight of the edge. For
instance, in Fig.~\ref{fig:shortest_path_program}~(a) we apply rule 1 in node
\texttt{@1} where two new \texttt{relax} facts are derived at node \texttt{@2}
and \texttt{@3}. Fig.~\ref{fig:shortest_path_program}~(b) is the result after
applying the same rule but at node \texttt{2}.

\begin{figure*}[ht]
\begin{center}
  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures/shortest2}}
  \hspace{0.4cm}
  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures/shortest3}}
  \hspace{0.4cm}
  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures/shortest8}}
\end{center}
\caption{Graphical representation of the SSSP program. Figure (a) represents the
   program after propagating initial distance at node \texttt{@1}, followed by
   Figure (b) where the first rule is applied in node \texttt{@3}. Figure (c)
   represents the state of the final program, where all the shortest paths
   have been computed.}
\label{fig:shortest_path_program}
\end{figure*}

The second rule of the program (lines 17-19) deals with the case where the new
distance in \texttt{relax} is not better than the current one, so it is thrown
away and the current distance is kept.

There many opportunities for concurrency in the SSSP program. For instance,
after applying rule 1 in Fig.~\ref{fig:shortest_path_program}~(a), it is
possible to either apply rules in either node \texttt{@2} or node
\texttt{@3}. In our implementation, we partition the graph into subgraphs that
are processed by multiple threads of execution. Eventually, it is no longer to
possible to apply rules and the final result present in
Fig.~\ref{fig:shortest_path_program}~(c) is achieved.

%On the other hand, LM has no natural matching of data and computation to workers (processes, threads),
%since nodes are a program abstraction and part of the program's logic.
%We view the set of nodes as a graph data structure where workers will perform work.
%A worker is able to process any node, although a node cannot be computed by more than one worker
%at the same time. This disallows the manipulation of a node by multiple workers.
