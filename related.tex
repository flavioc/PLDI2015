There has been an increasing interest in declarative and data-centric
languages. MapReduce~\cite{Dean:2008:MSD:1327452.1327492}, for instance, is a
popular data-centric programming model that is optimized for large clusters. The
scheduling and data sharing model is very simple: in the \emph{map phase}, data
is transformed at each node and the result reduced to a final result in the
\emph{reduce phase}. In order to facilitate the writing of programs over large
datasets, SQL-like languages such as
PigLatin~\cite{Olston:2008:PLN:1376616.1376726} have been developed.
PigLatin builds on top of MapReduce and allows the programmer to write complex
data-flow graphs, increasing the abstraction of the MapReduce paradigm.
An alternative to PigLatin/MapReduce is
Dryad~\cite{Isard:2007:DDD:1272996.1273005}
that allows programmers to design arbitrary computation patterns using the DAG
abstraction. It combines computational vertices with communication channels
(edges). Dryad programs are automatically scheduled to run on multiple
computers/cores and data is partitioned automatically during runtime.

Many programming languages follow the so-called \emph{coordination
paradigm}~\cite{Papadopoulos98coordinationmodels}, a form of distributed
programming that divides execution in two parts: \emph{computation}, where the actual
computation is performed, and \emph{coordination}, which deals with
communication and cooperation between processing units. This paradigm attempts
to clearly distinguish between these two parts by providing abstractions for
coordination in an attempt to provide architecture and system-independent forms
of communication.  

Linda~\cite{linda} is arguably the most famous coordination model. Linda
implements a data-driven coordination model and features a \emph{tuple space}
that can be manipulated using the following coordination directives:
\texttt{out(t)} to write a tuple \texttt{t} into the tuple space; \texttt{in(t)}
to read a tuple using the template \texttt{t}; \texttt{rd(t)} to retrieve a copy of
the tuple \texttt{t} from the tuple space; and \texttt{eval(p)} to add a process
\texttt{p} in the tuple space and execute it in parallel. 
Linda is be implemented on top of many
popular languages by simply creating a communication and storage mechanism for
the tuple space and then adding the directives as a language library.

Another early coordination language is Delirium~\cite{Delirium}. Unlike
Linda which is embbeded into another language, Delirium actually embeds
operators written in other languages inside the Delirium language.
The advantages of Delirium are improved abstraction
and easier debugging because sequential operators are isolated from the
coordination language.

Linda and Delirium are limited in the sense that the programmer can only
coordinate the scheduling of processing units, while the placement of data is
left to the implementation. LM differs from those languages since it
is fully data-driven and coordination acts on data instead of processing units.
The abstraction is then raised by considering data and algorithmic aspects of
the program instead of focusing how processing units are used.
Furthermore, the LM language is both a coordination language and a computation
language and there is no distinction between the two components.

Forward-chaining logic programming was made famous by the Datalog
language~\cite{Ullman:1990:PDK:533142}.  Traditionally used in deductive
databases, it is now being increasingly used in different fields such as
distributed networking~\cite{Loo-condie-garofalakis-p2}, sensor
nets~\cite{Chu:2007:DID:1322263.1322281} and cloud computing~\cite{alvaro:boom}.
LM itself is inspired in Meld~\cite{ashley-rollman-iclp09}, a Datalog-like language for
programming distributed emsembles of modular robots. Meld introduced the idea of
sensing and action facts in order to sense and act on the outside world,
respectively. Coordination facts are inspired in the same principles but are
used for coordinating data and computation.
