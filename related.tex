There has been an increasing interest in declarative and data-centric
languages. MapReduce~\cite{Dean:2008:MSD:1327452.1327492}, for instance, is a
popular data-centric programming model that is optimized for large clusters. The
scheduling and data sharing model is very simple: in the \emph{map phase}, data
is transformed at each node and the result reduced to a final result in the
\emph{reduce phase}. In order to facilitate the writing of programs over large
datasets, SQL-like languages such as
PigLatin~\cite{Olston:2008:PLN:1376616.1376726} have been developed.
PigLatin automatically compiles declarative code into physical plans
that are executed over Hadoop but provides very little control to the
programmer.

A declarative approach that is regaining popularity is
Datalog~\cite{Ullman:1990:PDK:533142}, also a forward-chaining logic programming
language. Traditionally used in deductive databases, it is now being increasingly used in different fields
such as distributed networking~\cite{Loo-condie-garofalakis-p2}, sensor
nets~\cite{Chu:2007:DID:1322263.1322281} and cloud computing~\cite{alvaro:boom}.
LM itself is inspired in P2~\cite{Loo-condie-garofalakis-p2} since it also models
programs as a graph structure. Another programming system that uses the graph
abstraction is Dryad~\cite{Isard:2007:DDD:1272996.1273005}, which combines computational vertices
with communication channels (edges) to form a data-flow graph. The program is
then scheduled to run on multiple computers/cores and data is partitioned
automatically during runtime.

Many programming languages follow the so-called \emph{coordination
paradigm}~\cite{Papadopoulos98coordinationmodels}, a form of distributed
programming that divides execution in two parts: \emph{computation}, where the actual
computation is performed, and \emph{coordination}, which deals with
communication and cooperation between processing units. This paradigm attempts
to clearly distinguish between these two parts by providing abstractions for
coordination in an attempt to provide architecture and system-independent forms
of communication.  

Linda~\cite{linda} is arguably the most famous coordination model. Linda
implements a data-driven coordination model and features a \emph{tuple space}
that can be manipulated using the following coordination directives:
\texttt{out(t)} to write a tuple \texttt{t} into the tuple space; \texttt{in(t)}
to read a tuple using the template \texttt{t}; \texttt{rd(t)} to retrieve a copy of
the tuple \texttt{t} from the tuple space; and \texttt{eval(p)} to add a process
\texttt{p} in the tuple space and execute it in parallel. 
Linda is be implemented on top of many
popular languages by simply creating a communication and storage mechanism for
the tuple space and then adding the directives as a language library.

Another important coordination language is Delirium~\cite{Delirium}. Unlike
Linda which is embbeded into another language, Delirium actually embeds
operators written in other languages inside the Delirium language.
The advantages of Delirium are improved abstraction
and easier debugging because sequential operators are isolated from the
coordination language.

Linda and Delirium are limited in the sense that the programmer can only
coordinate the scheduling of processing units, while the placement of data is
left to the implementation. LM also differs from those languages since it
raises the abstraction level from the processing units to nodes of a graph.
Furthermore, the LM language is both a coordination language and a computation
language and there is no distinction between the two components.

\iffalse
GraphLab~\cite{GraphLab2010} is a C++ framework for developing parallel machine
learning algorithms. GraphLab allows nodes to
have read/write access to different scopes through different concurrent access
models in order to balance performance and data consistency. While some programs
only need to access the local node's data, others may need to update edge
information. Each consistency model will provide different guarantees that are
better adapted to some algorithms. GraphLab provides different schedulers
that dictate the order in which node's are computed, which is a rudimentary form
of coordination. Later in this paper, we will show how certain GraphLab's
schedulers can be easily implemented in LM through the use of coordination
facts.
\fi
