The MiniMax algorithm is a decision rule algorithm for minimizing the
possible loss for a worst case (maximum loss) scenario in a zero sum
game for 2 (or more) players that play in
turns~\cite{Edwards54}.

The algorithm proceeds by building a game tree, where each tree node represents a
game state and the children represent the possible game moves that can
be made by either player 1 or player 2.
An evaluation function \texttt{f(State)} is used to compute the score of
the board for each leaf of the tree. A node is a leaf when the game state can no longer be
expanded. Finally, the
algorithm recursively minimizes or maximizes the scores of each node.
To select the best move for player 1, the
algorithm picks the move maximized at the root node.

In LM, the program starts with a root node (with the initial game state)
that is expanded with the available moves at each level. The graph of the
program is dynamic since nodes are created and then deleted once they are no
longer needed. The latter happens when the
leaf scores are computed or when a node fully minimizes or maximizes the
children scores. When the program ends, only the root node has facts in its
database.

The code in Fig.~\ref{minimax:check-end} shows part of the program.
The first three rules (lines 1-10) deal
with the case where no children nodes are created and the last three rules
(12-29) deal with the cases for creating new nodes.
The rule in lines 12-25 generates new nodes using the
\texttt{exists} language construct, which creates a new node address
\texttt{B}, where a new \texttt{play} fact is created with the a
board. A \texttt{parent(B,A)} fact is derived to allow node \texttt{B} to
communicate with its parent.

As noted before in Section~\ref{sec:fifo}, the runtime schedules nodes by XXX,
in a FIFO ordering for nodes,
meaning that when children are expanded, we first expand the children and
then the children of the children. In this case, the defined ordering
is not optimal for since the complete tree needs
to be expanded before computing the scores at the leaves. The memory
complexity of the program is $\mathcal{O}(n)$, where $n$ is the number of nodes
in the tree.

\begin{figure}[h!]
\scriptsize\begin{Verbatim}[numbers=left,commandchars=\\\{\}]
expand(A, Board, [], 0, P, \underline{Depth})
  -o leaf(A, Board).

expand(A, Board, [], N, P, \underline{Depth}),
N > 0, P = player1
  -o maximize(A, N, -00, 0).

expand(A, Board, [], N, P, \underline{Depth}),
N > 0, P = player2
  -o minimize(A, N, +00, 0).

expand(A, Board, [0 | Xs], N, P, Depth),
Depth >= 5
  -o exists B. (\underline{set-static(B)},
       \underline{set-default-priority(B, float(Depth + 1))},
       play(B, Board ++ [P | Xs], next(P), \underline{Depth + 1}),
       expand(A, Board ++ [0], Xs, N + 1, P, \underline{Depth}),
       parent(B, A)).

expand(A, Board, [0 | Xs], N, P, Depth),
Depth < 5
  -o exists B. (\underline{set-default-priority(B, float(Depth + 1))},
       play(B, Board ++ [P | Xs], next(P), \underline{Depth + 1}),
       expand(A, Board ++ [0], Xs, N + 1, P, \underline{Depth}),
       parent(B, A)).

expand(A, Board, [C | Xs], N, P, \underline{Depth})
C <> 0
  -o expand(A, Board ++ [C], Xs, N, P, \underline{Depth}).
\end{Verbatim}
\caption{MiniMax: checking if the game has ended and expanding the tree}
\label{minimax:check-end}
\end{figure}
\normalsize

With coordination, we set the priority nodes to be the same as the
depth so that the tree is expanded in a depth-first fashion (lines 15 and 22).
The memory complexity of the program then becomes $\mathcal{O}(d t)$, where $d$
is the depth of the tree and $t$ is the number of threads. As an example,
consider a system with 2 threads, $T_1$ and $T_2$, where $T_1$ first expands the root
node and then the first child. Since $T_2$ is idle, it steals half of the root's
children nodes and starts expanding one of the nodes in a depth-first fashion.
Since threads prioritize deeper nodes, the scores of the first leaves are immediatelly
computed and then sent to the parent node. At this point, the leaves are deleted
and reused for other nodes in the tree, resulting in minimal memory usage.

\iffalse
\begin{figure}[h!]
   \begin{center}
      \includegraphics[width=4.5cm]{figures/minimax_tree}
   \end{center}
   \caption{Expanding the MiniMax tree using coordination. By prioritizing
      deeper nodes, threads are forced to expand the tree using a depth-first
      approach, which is superior since there is no need to expand the whole
      tree before computing the node scores.}
   \label{fig:minimax}
\end{figure}
\fi

We also take advantage of memory locality by using \texttt{set-static} (line
14), so that nodes after a certain level are not stolen by other threads. While
this is not critical for performance in shared memory systems where node
stealing is fairly efficient, we expect that such coordination to be critical in
distributed systems.

\begin{figure}[h!]
   \begin{center}
      \subfloat[]{\small\begin{tabular}[b]{ | c | c | c |}
         \hline                       
         \textbf{\# T} & \textbf{R} & \textbf{C} \\ \hline \hline
         1 & 11.80GB & 0.50MB \\ \hline
         2 & 12.19GB & 1.45MB \\ \hline
         4 & 13.82GB & 2.35MB \\ \hline
         8 & 14.87GB & 4.36MB \\ \hline
         16 & 13.79GB & 8.1MB \\ \hline
         \end{tabular}
         \normalsize
      }
      \subfloat[]{\includegraphics[width=4.5cm]{results/min-max-tictactoe.png}}
   \end{center}
   \caption{Memory usage and scalability of the regular and coordinated versions
      of MiniMax.}
   \label{results:memory_minmax}
\end{figure}

In Fig.~\ref{results:memory_minmax} we compare the memory usage and scalability
of the coordinated MiniMax against the regular MiniMax. The coordinated version
sees a huge reduction of memory usage, needing at most 8MB for 16 threads, while
the regular version needs almost 14GB. Note that as the number of threads goes
up, memory usage also goes up. This is an artifact of our parallel memory
allocator that allocates large chunks of memory beforehand.
In terms of scalability, our experimental results show a 14-fold speedup for the
coordinated version against a 12-fold for the regular version when using 16
threads. When comparing the two versions directly, there is a 20\% run time
reduction when using 16 threads in the coordinated version.
